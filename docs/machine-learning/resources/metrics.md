---
title: ML.NET ölçümleri
description: ML.NET model performansını değerlendirmek için kullanılan ölçüleri anlama
ms.date: 04/29/2019
author: ''
ms.openlocfilehash: d76cab0b56085ebf2ee69f4d9d12c9685c3cb021
ms.sourcegitcommit: 4c10802ad003374641a2c2373b8a92e3c88babc8
ms.translationtype: MT
ms.contentlocale: tr-TR
ms.lasthandoff: 05/08/2019
ms.locfileid: "65452699"
---
# <a name="model-evaluation-metrics-in-mlnet"></a><span data-ttu-id="f3999-103">Modeli değerlendirme ML.NET ölçümlerde</span><span class="sxs-lookup"><span data-stu-id="f3999-103">Model evaluation metrics in ML.NET</span></span>

## <a name="metrics-for-binary-classification"></a><span data-ttu-id="f3999-104">İkili sınıflandırma için ölçümleri</span><span class="sxs-lookup"><span data-stu-id="f3999-104">Metrics for Binary Classification</span></span>

| <span data-ttu-id="f3999-105">Ölçümler</span><span class="sxs-lookup"><span data-stu-id="f3999-105">Metrics</span></span>   |      <span data-ttu-id="f3999-106">Açıklama</span><span class="sxs-lookup"><span data-stu-id="f3999-106">Description</span></span>      |  <span data-ttu-id="f3999-107">Aramak</span><span class="sxs-lookup"><span data-stu-id="f3999-107">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="f3999-108">**Doğruluğu**</span><span class="sxs-lookup"><span data-stu-id="f3999-108">**Accuracy**</span></span> |  <span data-ttu-id="f3999-109">[Doğruluk](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) olan bir sınama veri kümesi ile doğru tahminler oranı.</span><span class="sxs-lookup"><span data-stu-id="f3999-109">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="f3999-110">Giriş örneklerin toplam sayısı için doğru tahminler sayısının oranıdır.</span><span class="sxs-lookup"><span data-stu-id="f3999-110">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="f3999-111">Yalnızca iyi çalışır olması durumunda her sınıfa ait örnek benzer sayısı.</span><span class="sxs-lookup"><span data-stu-id="f3999-111">It works well only if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="f3999-112">**1,00, daha iyi yakın**.</span><span class="sxs-lookup"><span data-stu-id="f3999-112">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="f3999-113">Ancak 1,00 tam olarak bir sorunu gösterir (genellikle: Etiket/hedef sızıntısı, aşırı sığdırma veya eğitim verileri ile test).</span><span class="sxs-lookup"><span data-stu-id="f3999-113">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="f3999-114">Test verilerini olduğunda (burada örneklerin çoğu sınıflardan birine ait) dengesiz, veri kümesi çok küçük veya doğruluğu, gerçekten sınıflandırıcı verimliliğini yakalamaz ve ek ölçümler denetlemek gereken puanları 0,00 veya 1,00, yaklaşan.</span><span class="sxs-lookup"><span data-stu-id="f3999-114">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is very small, or scores approach 0.00 or 1.00, then accuracy doesn’t really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="f3999-115">**AUC**</span><span class="sxs-lookup"><span data-stu-id="f3999-115">**AUC**</span></span> |    <span data-ttu-id="f3999-116">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) veya *eğri alanında*: Bu, gerçek pozitif sonuç oranına hatalı pozitif sonuç oranı karşılaştırması Süpürme tarafından oluşturulan eğri alanında ölçme.</span><span class="sxs-lookup"><span data-stu-id="f3999-116">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve*: This is measuring the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="f3999-117">**1,00, daha iyi yakın**.</span><span class="sxs-lookup"><span data-stu-id="f3999-117">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="f3999-118">Kabul edilebilir bir model için 0,50 büyük olmalıdır; bir model AUC 0,50 veya daha az ile işe yaramaz.</span><span class="sxs-lookup"><span data-stu-id="f3999-118">It should be greater than 0.50 for a model to be acceptable; a model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="f3999-119">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="f3999-119">**AUCPR**</span></span> | <span data-ttu-id="f3999-120">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) veya *eğrinin duyarlık geri çekme eğrinin alanında*: Sınıfları çok imbalanced (yüksek oranda dengesiz veri kümeleri) olduğunda tahmin başarısını yararlı ölçüsü.</span><span class="sxs-lookup"><span data-stu-id="f3999-120">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are very imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="f3999-121">**1,00, daha iyi yakın**.</span><span class="sxs-lookup"><span data-stu-id="f3999-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="f3999-122">Yüksek puan yakın sınıflandırıcı (Yüksek duyarlılık) doğru sonuçlar döndüren yanı sıra, tüm pozitif sonuçlar (yüksek geri çağırma) çoğunu döndüren 1.00 göster.</span><span class="sxs-lookup"><span data-stu-id="f3999-122">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="f3999-123">**F1 puanı**</span><span class="sxs-lookup"><span data-stu-id="f3999-123">**F1-score**</span></span> | <span data-ttu-id="f3999-124">[F1 puanı](https://en.wikipedia.org/wiki/F1_score) olarak da bilinen *puanı F veya F ölçümü dengeli*.</span><span class="sxs-lookup"><span data-stu-id="f3999-124">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="f3999-125">Bu geri çağırma ve duyarlık harmonik olur.</span><span class="sxs-lookup"><span data-stu-id="f3999-125">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="f3999-126">F1 puanı, duyarlık ve geri çağırma arasında bir denge arama istediğinizde yararlıdır.</span><span class="sxs-lookup"><span data-stu-id="f3999-126">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="f3999-127">**1,00, daha iyi yakın**.</span><span class="sxs-lookup"><span data-stu-id="f3999-127">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="f3999-128">F1 puanı 1.00 ve en kötü puanı 0,00 en iyi değerini ulaşır.</span><span class="sxs-lookup"><span data-stu-id="f3999-128">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="f3999-129">Bu durum, sınıflandırıcınızı nasıl hassas olduğunu bildirir.</span><span class="sxs-lookup"><span data-stu-id="f3999-129">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="f3999-130">İkili sınıflandırma ilgili diğer ayrıntılar için aşağıdaki makalelere ölçümleri okuyun:</span><span class="sxs-lookup"><span data-stu-id="f3999-130">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="f3999-131">Doğruluk, kesinlik, geri çağırma veya F1?</span><span class="sxs-lookup"><span data-stu-id="f3999-131">Accuracy, Precision, Recall or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="f3999-132">İkili sınıflandırma ölçümleri sınıfı</span><span class="sxs-lookup"><span data-stu-id="f3999-132">Binary Classification Metrics class</span></span>](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.binaryclassificationmetrics?view=ml-dotnet)
- [<span data-ttu-id="f3999-133">Duyarlık geri çekme ve ROC eğrileri arasındaki ilişki</span><span class="sxs-lookup"><span data-stu-id="f3999-133">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="metrics-for-multi-class-classification"></a><span data-ttu-id="f3999-134">Çok sınıflı sınıflandırma için ölçümleri</span><span class="sxs-lookup"><span data-stu-id="f3999-134">Metrics for Multi-class Classification</span></span>

| <span data-ttu-id="f3999-135">Ölçümler</span><span class="sxs-lookup"><span data-stu-id="f3999-135">Metrics</span></span>   |      <span data-ttu-id="f3999-136">Açıklama</span><span class="sxs-lookup"><span data-stu-id="f3999-136">Description</span></span>      |  <span data-ttu-id="f3999-137">Aramak</span><span class="sxs-lookup"><span data-stu-id="f3999-137">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="f3999-138">**Mikro doğruluğu**</span><span class="sxs-lookup"><span data-stu-id="f3999-138">**Micro-Accuracy**</span></span> |  <span data-ttu-id="f3999-139">[Micro-ortalama kesinlik](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.multiclassclassificationmetrics.microaccuracy?view=ml-dotnet) ortalama ölçüsünü hesaplamak için tüm sınıflar Katkıların toplar.</span><span class="sxs-lookup"><span data-stu-id="f3999-139">[Micro-average Accuracy](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.multiclassclassificationmetrics.microaccuracy?view=ml-dotnet) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="f3999-140">Doğru şekilde tahmin edilen örnekler bir bölümüdür.</span><span class="sxs-lookup"><span data-stu-id="f3999-140">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="f3999-141">Micro-ortalama sınıfı üyelik dikkate almaz.</span><span class="sxs-lookup"><span data-stu-id="f3999-141">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="f3999-142">Temel olarak, her örnek sınıfı çifti eşit doğruluğu ölçüme katkıda bulunur.</span><span class="sxs-lookup"><span data-stu-id="f3999-142">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="f3999-143">**1,00, daha iyi yakın**.</span><span class="sxs-lookup"><span data-stu-id="f3999-143">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="f3999-144">Sınıf dengesizliği (yani olabilir şüpheleniyorsanız bir çok sınıflı sınıflandırma görevde micro doğruluğu makrosu doğruluğu tercih edilir</span><span class="sxs-lookup"><span data-stu-id="f3999-144">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="f3999-145">"bir sınıfı diğer sınıfların çok daha fazla örnek olabilir).</span><span class="sxs-lookup"><span data-stu-id="f3999-145">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="f3999-146">**Doğruluk makrosu**</span><span class="sxs-lookup"><span data-stu-id="f3999-146">**Macro-Accuracy**</span></span> | <span data-ttu-id="f3999-147">[Makro ortalama kesinlik](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.multiclassclassificationmetrics.macroaccuracy?view=ml-dotnet) sınıf düzeyinde ortalama kesinlik olduğunu.</span><span class="sxs-lookup"><span data-stu-id="f3999-147">[Macro-average Accuracy](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.multiclassclassificationmetrics.macroaccuracy?view=ml-dotnet) is the average accuracy at the class level.</span></span> <span data-ttu-id="f3999-148">Her sınıf için doğruluğu hesaplanır ve makrosu doğruluğu bu doğruluk ortalamasıdır.</span><span class="sxs-lookup"><span data-stu-id="f3999-148">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="f3999-149">Temel olarak, her sınıf eşit doğruluğu ölçüme katkıda bulunur.</span><span class="sxs-lookup"><span data-stu-id="f3999-149">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="f3999-150">Azınlık sınıfları daha büyük bir sınıf olarak eşit ağırlık verilir.</span><span class="sxs-lookup"><span data-stu-id="f3999-150">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="f3999-151">Makro ortalama ölçüm ağırlık olanlardan kaç tane bağımsız olarak veri kümesi sınıfı içeriyor. her sınıf sağlar.</span><span class="sxs-lookup"><span data-stu-id="f3999-151">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="f3999-152">**1,00, daha iyi yakın**.</span><span class="sxs-lookup"><span data-stu-id="f3999-152">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="f3999-153">Ölçüm bağımsız olarak her sınıf için hesaplar ve ardından (Bu nedenle tüm sınıflar eşit olarak değerlendirmek) ortalamasını alır.</span><span class="sxs-lookup"><span data-stu-id="f3999-153">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="f3999-154">**Günlük kaybı**</span><span class="sxs-lookup"><span data-stu-id="f3999-154">**Log-loss**</span></span>| <span data-ttu-id="f3999-155">[Logaritmik kaybı](http://wiki.fast.ai/index.php/Log_Loss) tahmin giriş 0,00 1,00 arasındaki bir olasılık değeri olduğu bir sınıflandırma modeli performansını ölçer.</span><span class="sxs-lookup"><span data-stu-id="f3999-155">[Logarithmic loss](http://wiki.fast.ai/index.php/Log_Loss) measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="f3999-156">Tahmin olasılık gerçek etiketten kareninkinden günlük kaybı artar.</span><span class="sxs-lookup"><span data-stu-id="f3999-156">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="f3999-157">**0,00, daha iyi yakın**.</span><span class="sxs-lookup"><span data-stu-id="f3999-157">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="f3999-158">Mükemmel bir model 0,00 kaybı oturum açması gerekir.</span><span class="sxs-lookup"><span data-stu-id="f3999-158">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="f3999-159">Bu değer en aza indirmek için makine öğrenimi modellerinin amacı olan.</span><span class="sxs-lookup"><span data-stu-id="f3999-159">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="f3999-160">**Günlük kaybı azaltma**</span><span class="sxs-lookup"><span data-stu-id="f3999-160">**Log-Loss Reduction**</span></span> | <span data-ttu-id="f3999-161">[Logaritmik kaybı azaltma](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.multiclassclassificationmetrics.loglossreduction?view=ml-dotnet) rasgele tahmin sınıflandırıcı avantajı olarak yorumlanabilir.</span><span class="sxs-lookup"><span data-stu-id="f3999-161">[Logarithmic loss reduction](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.multiclassclassificationmetrics.loglossreduction?view=ml-dotnet) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="f3999-162">**Aralıkları -INF ve burada 1,00 mükemmel Öngörüler ve 0,00 gösterir ortalama Öngörüler 1,00**.</span><span class="sxs-lookup"><span data-stu-id="f3999-162">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="f3999-163">Değer 0,20 eşitse "doğru bir tahmin olasılığını %20 rasgele tahmin daha iyi olduğu gibi" Örneğin, bu yorumlanabilir</span><span class="sxs-lookup"><span data-stu-id="f3999-163">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="f3999-164">Mikro doğruluğu genellikle daha iyi iş gereksinimlerine göre ML Öngörüler hizalanır.</span><span class="sxs-lookup"><span data-stu-id="f3999-164">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="f3999-165">Bir çok sınıflı sınıflandırma görevi kalitesini seçmeye yönelik tek bir ölçüm seçmek istiyorsanız, bu genellikle mikro doğruluğu olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="f3999-165">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="f3999-166">Örneğin, bir destek bileti sınıflandırma görevi: (takımları desteklemek için gelen biletleri eşlenir)</span><span class="sxs-lookup"><span data-stu-id="f3999-166">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="f3999-167">Micro-doğruluğu--ne sıklıkta gelen bir bilet doğru ekibe sınıflandırılmış?</span><span class="sxs-lookup"><span data-stu-id="f3999-167">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="f3999-168">Makro doğruluk--ortalama bir takımda, ne sıklıkta gelen bir bilet ekip için doğru mu?</span><span class="sxs-lookup"><span data-stu-id="f3999-168">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="f3999-169">Bu örnekte küçük ekipler makrosu doğruluğu overweights; yıl 10 k büyük bir takımla biletleri kadar yıl başına yalnızca 10 biletleri alır, küçük bir takımda sayar.</span><span class="sxs-lookup"><span data-stu-id="f3999-169">Macro-accuracy overweights small teams in this example; a small team which gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="f3999-170">Mikro doğruluğu bu durumda daha iyi iş gereksinimlerini, "ne kadar zaman/para kaydetme şirket bilet yönlendirme işlemi otomatik hale getirerek olabilir" ile ilişkilendirir.</span><span class="sxs-lookup"><span data-stu-id="f3999-170">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="f3999-171">Çok sınıflı sınıflandırma ilgili diğer ayrıntılar için aşağıdaki makalelere ölçümleri okuyun:</span><span class="sxs-lookup"><span data-stu-id="f3999-171">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="f3999-172">Micro - ve makro-ortalama duyarlık geri çekme ve F puanı</span><span class="sxs-lookup"><span data-stu-id="f3999-172">Micro- and Macro-average of Precision, Recall and F-Score</span></span>](http://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="f3999-173">Imbalanced kümesiyle sınıflı sınıflandırma</span><span class="sxs-lookup"><span data-stu-id="f3999-173">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="metrics-for-regression"></a><span data-ttu-id="f3999-174">Regresyon için ölçümleri</span><span class="sxs-lookup"><span data-stu-id="f3999-174">Metrics for Regression</span></span>

| <span data-ttu-id="f3999-175">Ölçümler</span><span class="sxs-lookup"><span data-stu-id="f3999-175">Metrics</span></span>   |      <span data-ttu-id="f3999-176">Açıklama</span><span class="sxs-lookup"><span data-stu-id="f3999-176">Description</span></span>      |  <span data-ttu-id="f3999-177">Aramak</span><span class="sxs-lookup"><span data-stu-id="f3999-177">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="f3999-178">**R karesi alınmış**</span><span class="sxs-lookup"><span data-stu-id="f3999-178">**R-Squared**</span></span> |  <span data-ttu-id="f3999-179">[R karesi alınmış (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), veya *katsayısı* - INF ve 1,00 arasında bir değer olarak Tahmine dayalı model gücünü temsil eder.</span><span class="sxs-lookup"><span data-stu-id="f3999-179">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="f3999-180">1,00 mükemmel bir uyum yoktur ve puanları negatif olabilir. Bu nedenle uygun arbitrarly kötü olabilir anlamına gelir.</span><span class="sxs-lookup"><span data-stu-id="f3999-180">1.00 means there is a perfect fit, and the fit can be arbitrarly poor so the scores can be negative.</span></span> <span data-ttu-id="f3999-181">0,00 anlamına gelir. bir puan modeli etiket için beklenen değer tahmin etme.</span><span class="sxs-lookup"><span data-stu-id="f3999-181">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="f3999-182">R2 ne kadar yakın gerçek test veri değerler için tahmin edilen değerler: ölçer.</span><span class="sxs-lookup"><span data-stu-id="f3999-182">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="f3999-183">**1,00, daha iyi kalite yakın**.</span><span class="sxs-lookup"><span data-stu-id="f3999-183">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="f3999-184">Ancak, bazen düşük R karesi alınmış değerleri (örneğin, 0,50) tamamen normal veya senaryonuz için yeterince iyi olabilir ve yüksek R karesi alınmış değer her zaman iyi değildir ve şüpheli.</span><span class="sxs-lookup"><span data-stu-id="f3999-184">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="f3999-185">**Mutlak kaybı**</span><span class="sxs-lookup"><span data-stu-id="f3999-185">**Absolute-loss**</span></span> |  <span data-ttu-id="f3999-186">[Mutlak kaybı](https://en.wikipedia.org/wiki/Mean_absolute_error) veya *ortalama mutlak hata (MAE)* tahminler elde etmek için gerçek sonuçların ne kadar yakın olan ölçer.</span><span class="sxs-lookup"><span data-stu-id="f3999-186">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="f3999-187">Bu model hataları model hatası tahmin edilen etiket değeri ile doğru etiket değeri arasındaki mutlak uzaklık olduğu ortalamasıdır.</span><span class="sxs-lookup"><span data-stu-id="f3999-187">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="f3999-188">Bu tahmin hata, test veri kümesinin her bir kayıt için hesaplanır.</span><span class="sxs-lookup"><span data-stu-id="f3999-188">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="f3999-189">Son olarak, ortalama değer için kaydedilen tüm mutlak hataların hesaplanır.</span><span class="sxs-lookup"><span data-stu-id="f3999-189">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="f3999-190">**0,00, daha iyi kalite yakın.**</span><span class="sxs-lookup"><span data-stu-id="f3999-190">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="f3999-191">Ortalama mutlak hata ölçülen veri aynı ölçeğini kullandığına dikkat edin (belirli bir aralık için normale döndürülemez).</span><span class="sxs-lookup"><span data-stu-id="f3999-191">Note that the mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="f3999-192">Mutlak kaybı Squared kaybı ve RMS kaybı yalnızca aynı veri kümesi veya veri kümesiyle bir smilar etiket değeri dağıtım modelleri arasında karşılaştırma yapmak için kullanılabilir.</span><span class="sxs-lookup"><span data-stu-id="f3999-192">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a smilar label value distribution.</span></span> |
| <span data-ttu-id="f3999-193">**Kare kaybı**</span><span class="sxs-lookup"><span data-stu-id="f3999-193">**Squared-loss**</span></span> |  <span data-ttu-id="f3999-194">[Squared kaybı](https://en.wikipedia.org/wiki/Mean_squared_error) veya *ortalama karesi alınmış hata (MSE)* ayrıca adlı veya *Ortalama kare sapma (MSD'yi)* , regresyon satır test veri değerlerini bir dizi için ne kadar yakın olduğunu bildirir.</span><span class="sxs-lookup"><span data-stu-id="f3999-194">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called or *Mean Squared Deviation (MSD)* tells you how close a regression line is to a set of test data values.</span></span> <span data-ttu-id="f3999-195">Bunu noktaları uzaklıkta (Bu uzaklığa "hatalar" olan) regresyon satırına almak ve bunları karesini yapar.</span><span class="sxs-lookup"><span data-stu-id="f3999-195">It does this by taking the distances from the points to the regression line (these distances are the “errors”) and squaring them.</span></span> <span data-ttu-id="f3999-196">Daha fazla ağırlık karesini büyük farklılıklar sağlar.</span><span class="sxs-lookup"><span data-stu-id="f3999-196">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="f3999-197">Her zaman negatif olmayan, ve **0,00 yakın değerler daha iyidir**.</span><span class="sxs-lookup"><span data-stu-id="f3999-197">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="f3999-198">Verilerinizi bağlı olarak, ortalama karesi alınmış hata için çok küçük bir değer almak mümkün olabilir.</span><span class="sxs-lookup"><span data-stu-id="f3999-198">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="f3999-199">**RMS kaybı**</span><span class="sxs-lookup"><span data-stu-id="f3999-199">**RMS-loss**</span></span> |  <span data-ttu-id="f3999-200">[RMS kaybı](https://en.wikipedia.org/wiki/Root-mean-square_deviation) veya *kök ortalama karesi alınmış hata (RMSE)* (olarak da adlandırılan *kök Ortalama kare sapma, RMSD*), bir model tarafından tahmin edilen değerler ve değerlerin birbirinden gerçekten ölçer Model alınmıştır ortamından gözlemledik.</span><span class="sxs-lookup"><span data-stu-id="f3999-200">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values actually observed from the environment that is being modeled.</span></span> <span data-ttu-id="f3999-201">RMS kaybı Squared kaybı kare kökünü ve aynı birim etiketi için mutlak kaybı benzer olarak daha fazla ağırlık vermek daha büyük farklılıklar da vardır.</span><span class="sxs-lookup"><span data-stu-id="f3999-201">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the abolute-loss though giving more weight to larger diferences.</span></span> <span data-ttu-id="f3999-202">Kök Ortalama kare hata, Deneysel sonuçları doğrulamak için climatology, tahmin ve gerileme analizini yaygın olarak kullanılır.</span><span class="sxs-lookup"><span data-stu-id="f3999-202">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="f3999-203">Her zaman negatif olmayan, ve **0,00 yakın değerler daha iyidir**.</span><span class="sxs-lookup"><span data-stu-id="f3999-203">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="f3999-204">RMSD ölçek bağımlı olduğu gibi belirli bir veri kümesi ve veri kümeleri arasında değil, farklı modelleri, tahmin hataları Karşılaştırılacak doğruluk ölçüsüdür.</span><span class="sxs-lookup"><span data-stu-id="f3999-204">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="f3999-205">Regresyon ölçümleri hakkında daha ayrıntılı bilgi için bu makaleleri okuyun:</span><span class="sxs-lookup"><span data-stu-id="f3999-205">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="f3999-206">Gerileme analizini: Nasıl R karesi alınmış yorumlar ve uygun olan özelliği değerlendirmek?</span><span class="sxs-lookup"><span data-stu-id="f3999-206">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="f3999-207">R kare gerilemesi analizi yorumlama</span><span class="sxs-lookup"><span data-stu-id="f3999-207">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="f3999-208">R karesi alınmış tanımı</span><span class="sxs-lookup"><span data-stu-id="f3999-208">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="f3999-209">Ortalama karesi alınmış hata tanımı</span><span class="sxs-lookup"><span data-stu-id="f3999-209">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="f3999-210">Ortalama karesi alınmış hata ve kök ortalama karesi alınmış hata nedir?</span><span class="sxs-lookup"><span data-stu-id="f3999-210">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)
